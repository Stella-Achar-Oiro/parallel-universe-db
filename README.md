# ðŸŒŒ Parallel Universe Database

> What if your database could exist in multiple realities?

Spawn instant database forks (parallel universes), deploy AI agents to each universe to test different optimization strategies, watch them compete in real-time, and promote the winner to production.

**Built for the [Agentic Postgres Challenge](https://dev.to/challenges/postgres)**

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Node](https://img.shields.io/badge/node-%3E%3D18-brightgreen)
![React](https://img.shields.io/badge/react-18.2.0-blue)

## ðŸŽ¯ What Makes This Special

- **Zero-Copy Forks**: Instant database forks without copying data (~1 second vs 30+ minutes)
- **AI Agent Competition**: 4 specialized agents compete in parallel to find the best optimization
- **Real-Time Visualization**: Watch optimizations happen live with beautiful animations
- **2,375x Cost Savings**: Pay $0.02 instead of $47.50 for testing 4 strategies
- **One-Click Promotion**: Apply winning optimizations to production instantly
- **Full Accessibility**: WCAG AA compliant with keyboard navigation and screen reader support

## ðŸš€ Quick Start

### Prerequisites

- Node.js 18+ and npm
- PostgreSQL 14+ with pgvector extension
- Anthropic API key (for AI agents)
- Tiger Cloud account (optional, for production forks)

### Installation

```bash
# Clone the repository
git clone https://github.com/Stella-Achar-Oiro/parallel-universe-db.git
cd parallel-universe-db

# Install backend dependencies
cd backend
npm install

# Install frontend dependencies
cd ../frontend
npm install
```

### Database Setup

```bash
# Create a PostgreSQL database
createdb parallel_universe_db

# Run schema
psql parallel_universe_db < database/schema.sql

# Seed with test data
psql parallel_universe_db < database/seed.sql
```

### Configuration

```bash
# Copy environment template
cp .env.example .env

# Edit .env and add:
# - DATABASE_URL: Your PostgreSQL connection string
# - ANTHROPIC_API_KEY: Your Anthropic API key
# - TIGER_SERVICE_ID: (Optional) Your Tiger Cloud service ID
```

### Running the Application

```bash
# Terminal 1: Start backend
cd backend
npm run dev

# Terminal 2: Start frontend
cd frontend
npm run dev
```

Visit http://localhost:5173 to see the application!

## ðŸ—ï¸ Architecture

### Backend (Node.js + Express)

```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ IndexAgent.js      # Tests different index strategies
â”‚   â”‚   â”œâ”€â”€ QueryAgent.js      # Rewrites and optimizes queries
â”‚   â”‚   â”œâ”€â”€ CacheAgent.js      # Creates materialized views
â”‚   â”‚   â””â”€â”€ SchemaAgent.js     # Optimizes schema structure
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ optimize.js        # Main optimization endpoint
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ tigerService.js    # Fork management wrapper
â”‚   â”‚   â””â”€â”€ mcpService.js      # AI-powered PostgreSQL expertise
â”‚   â””â”€â”€ server.js              # Express server
```

### Frontend (React + Vite + Tailwind)

```
frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ UniverseSpawner.jsx    # Main optimization UI
â”‚   â”‚   â”œâ”€â”€ UniverseCard.jsx       # Individual universe display
â”‚   â”‚   â”œâ”€â”€ PerformanceChart.jsx   # Results visualization
â”‚   â”‚   â””â”€â”€ CostCalculator.jsx     # Cost savings display
â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â””â”€â”€ useOptimization.js     # API integration hook
â”‚   â””â”€â”€ App.jsx                    # Main application
```

## ðŸŽ® How It Works

1. **Describe Problem**: User enters a database performance issue
2. **Select Strategies**: Choose which optimization approaches to test (Index, Query, Cache, Schema)
3. **Spawn Universes**: System creates 4 instant zero-copy database forks
4. **Run Agents**: AI agents compete in parallel, each testing different optimizations
5. **Compare Results**: Real-time visualization shows performance improvements
6. **Promote Winner**: One-click promotion of best optimization to production

## ðŸ¤– AI Agents

### IndexAgent
- Analyzes pg_stat_statements for slow queries
- Uses Claude to recommend optimal indexes
- Tests B-tree, GiST, GIN, and BRIN indexes
- Measures performance before/after

### QueryAgent
- Identifies query bottlenecks with EXPLAIN ANALYZE
- Rewrites queries for better performance
- Tests CTE vs subquery patterns
- Optimizes JOIN order

### CacheAgent
- Finds frequently accessed data
- Creates materialized views
- Implements smart caching strategies
- Reduces query load

### SchemaAgent
- Analyzes table structures
- Adds optimal constraints
- Updates statistics with ANALYZE
- Optimizes storage with VACUUM

## ðŸŽ¨ Features

### Accessibility (WCAG AA Compliant)
- âœ… Semantic HTML structure
- âœ… Keyboard navigation throughout
- âœ… ARIA labels on all interactive elements
- âœ… Screen reader tested
- âœ… 4.5:1 color contrast minimum
- âœ… Focus indicators on all focusable elements

### Technologies Used

**Backend:**
- Express.js - API server
- pg - PostgreSQL client
- Anthropic SDK - AI-powered optimization
- dotenv - Environment management

**Frontend:**
- React 18 - UI framework
- Vite - Build tool
- Tailwind CSS - Styling
- Framer Motion - Animations
- Recharts - Data visualization
- Lucide React - Icons

**Database:**
- PostgreSQL 14+
- pg_stat_statements - Query analysis
- pgvector - Hybrid search (future feature)

## ðŸ“Š Performance Metrics

Based on our e-commerce demo dataset:

- **100,000 users**
- **500,000 orders**
- **1,000,000 order items**
- **1,000 products**

Typical improvements:
- Index optimization: 70-90% faster queries
- Query rewriting: 50-70% improvement
- Caching: 40-60% reduction in load
- Schema optimization: 30-50% better planning

## ðŸ’¡ Use Cases

1. **Development Testing**: Try different optimization strategies without affecting production
2. **A/B Testing**: Compare multiple approaches simultaneously
3. **Performance Tuning**: Find the best optimization for your specific workload
4. **Learning**: Understand how different optimizations affect performance
5. **Cost Optimization**: Test strategies without expensive database clones

## ðŸ”® Future Enhancements

- [ ] Hybrid search integration (BM25 + vector search for finding similar past optimizations)
- [ ] Persistent memory (agents learn from past optimizations)
- [ ] More agent types (PartitionAgent, ConnectionPoolAgent)
- [ ] Real-time streaming updates via WebSockets
- [ ] Multi-database support (MySQL, MongoDB)
- [ ] Slack/Discord notifications
- [ ] Automated scheduling for routine optimization

## ðŸ¤ Contributing

This is a competition submission, but feedback is welcome! Feel free to:
- Open issues for bugs or suggestions
- Star the repo if you find it interesting
- Share with others who might benefit

## ðŸ“ License

MIT License - see LICENSE file for details

## ðŸ™ Acknowledgments

- **Tiger Cloud** for zero-copy fork technology
- **Anthropic** for Claude AI capabilities
- **DEV Community** for hosting the challenge
- **PostgreSQL** for being an amazing database

## ðŸ‘©â€ðŸ’» Author

**Stella Achar Oiro**

- GitHub: [@Stella-Achar-Oiro](https://github.com/Stella-Achar-Oiro)
- Built for: Agentic Postgres Challenge 2024

---

**Built with â¤ï¸ using Agentic Postgres, Tiger Cloud, and Claude AI**

*Making database optimization feel like magic* âœ¨
